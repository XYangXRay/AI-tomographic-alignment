{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b87aa476",
   "metadata": {},
   "source": [
    "# 3D Convolutional Neural Network for Tomographic Alignment\n",
    "\n",
    "## Expanding the Network: ResNet and Engineering the Data Again\n",
    "\n",
    "Since based on previous analysis it is likely that the network was too small to properly identify the features necessary for alignment, the next logical step is to expand the network. Making deeper neural networks usually results in diminishing returns, but residual neural networks have proven to successfully allow for deeper neural networks. Now this model structure will be used in order to find some form of convergence.\n",
    "\n",
    "While it seems like the ResNet will increase the performance of the model on larger training sets, testing convergence is still a major problem. Now the input data will be modified to find the difference between each projection which should help the network better isolate the pattern we want it to find. This will hopefully allow for better understanding of the specific alignment problem by the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83d27f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential packages\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import tomography and imaging packages\n",
    "import tomopy\n",
    "from skimage.transform import rotate, AffineTransform\n",
    "from skimage import transform as tf\n",
    "\n",
    "# Import neural net packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.profiler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb5db9bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working Environment: pytorch\n",
      "Cuda Version: 11.8\n",
      "Cuda Availability: True\n",
      "/home/liam/Projects/Tomographic Alignment\r\n"
     ]
    }
   ],
   "source": [
    "# Checking to ensure environment and cuda are correct\n",
    "print(\"Working Environment: {}\".format(os.environ['CONDA_DEFAULT_ENV']))\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "print(\"Cuda Version: {}\".format(torch.version.cuda))\n",
    "print(\"Cuda Availability: {}\".format(torch.cuda.is_available()))\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1876ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The resulting function that can be used for modifying the data\n",
    "def data_mean_difference(data):\n",
    "    \n",
    "    # Create copy of dataset for projections to be modified, also initializes array for mean projections\n",
    "    projections = data[:, 0].copy()\n",
    "    mean_projections = np.zeros((projections.shape[0]), dtype = object)\n",
    "    \n",
    "    # Iterate through each projection stack\n",
    "    for i in range (projections.shape[0]):\n",
    "\n",
    "        # Get rid of extra dimensions for neural networks and create a mean projection\n",
    "        projections[i] = np.squeeze(projections[i])\n",
    "        mean_projections[i] = np.mean(projections[i], axis = 0)\n",
    "\n",
    "        # Iterate through every projection in stack\n",
    "        for j in range (projections[0].shape[0]):\n",
    "\n",
    "            # Change current projection to difference between current projection and mean projection\n",
    "            projections[i][j] = projections[i][j] - mean_projections[i]\n",
    "            \n",
    "        # Expand dimensions to original form for neural networks\n",
    "        projections[i] = np.expand_dims(projections[i], axis = 0)\n",
    "        projections[i] = np.expand_dims(projections[i], axis = 0)\n",
    "\n",
    "    # Create data difference array\n",
    "    data_diff = data.copy()\n",
    "\n",
    "    # Replace all data with the new difference projections\n",
    "    for i in range (data.shape[0]):\n",
    "\n",
    "        data_diff[i][0] = projections[i]\n",
    "        \n",
    "    return data_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "117fbef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_difference(data, entries):\n",
    "\n",
    "    data_diff = np.zeros((data.shape), dtype = object)\n",
    "    projections = []\n",
    "\n",
    "    for i in range (entries):\n",
    "        projections.append(np.squeeze(data[:, 0][i]))\n",
    "\n",
    "    projections = np.asarray(projections)\n",
    "\n",
    "    differences = np.zeros((entries, projections[0].shape[0] - 1), dtype = object)\n",
    "\n",
    "    for i in range (entries):\n",
    "\n",
    "        for j in range (projections[0].shape[0] - 1):\n",
    "\n",
    "            differences[i, j] = (projections[i][j + 1] - projections[i][j])\n",
    "\n",
    "    for i in range (data_diff.shape[0]):\n",
    "\n",
    "        data_diff[i][0] = np.zeros((differences.shape[1], differences[0, 0].shape[0], differences[0,0].shape[1]))\n",
    "        data_diff[i][1] = data[i][1]\n",
    "\n",
    "        for j in range (projections[0].shape[0] - 1):\n",
    "\n",
    "            data_diff[i][0][j] = differences[i, j]\n",
    "\n",
    "        data_diff[i][0] = np.expand_dims(data_diff[i][0], axis = 0)\n",
    "        data_diff[i][0] = np.expand_dims(data_diff[i][0], axis = 0)\n",
    "\n",
    "    return data_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2df2f60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data, 25 entries of 128 resolution shepp3ds\n",
    "res = 128\n",
    "entries = 1250\n",
    "data = []\n",
    "\n",
    "for i in range(entries):\n",
    "    data.append(np.load('./shepp{}-{}/shepp{}-{}_{}.npy'.format(res, entries, res, entries, i), \n",
    "                        allow_pickle = True))\n",
    "    \n",
    "data = np.asarray(data)\n",
    "\n",
    "\n",
    "# data = data_mean_difference(data)\n",
    "data = data_difference(data, entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98c8c622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Training Dataset: (1000, 2)\n",
      "Shape of Testing Dataset: (250, 2)\n"
     ]
    }
   ],
   "source": [
    "# Checking shape of training and testing splits\n",
    "trainset, testset = np.split(data, [int(entries * 4 / 5)])\n",
    "print(\"Shape of Training Dataset: {}\".format(trainset.shape))\n",
    "print(\"Shape of Testing Dataset: {}\".format(testset.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cb3e931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "def norm(proj):\n",
    "    proj = (proj - torch.min(proj)) / (torch.max(proj) - torch.min(proj))\n",
    "    return proj\n",
    "\n",
    "# Get inplanes for resnet\n",
    "def get_inplanes():\n",
    "    return [64, 128, 256, 512]\n",
    "\n",
    "\n",
    "# Preset for a 3x3x3 kernel convolution\n",
    "def conv3x3x3(in_planes, out_planes, stride=1):\n",
    "    return nn.Conv3d(in_planes,\n",
    "                     out_planes,\n",
    "                     kernel_size=3,\n",
    "                     stride=stride,\n",
    "                     padding=1,\n",
    "                     bias=False)\n",
    "\n",
    "\n",
    "# Preset for a 1x1x1 kernel convolution\n",
    "def conv1x1x1(in_planes, out_planes, stride=1):\n",
    "    return nn.Conv3d(in_planes,\n",
    "                     out_planes,\n",
    "                     kernel_size=1,\n",
    "                     stride=stride,\n",
    "                     bias=False)\n",
    "\n",
    "# Basic block for resnet\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1, downsample=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = conv3x3x3(in_planes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm3d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm3d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "    \n",
    "# Bottleneck block for resnet\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1, downsample=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = conv1x1x1(in_planes, planes)\n",
    "        self.bn1 = nn.BatchNorm3d(planes)\n",
    "        self.conv2 = conv3x3x3(planes, planes, stride)\n",
    "        self.bn2 = nn.BatchNorm3d(planes)\n",
    "        self.conv3 = conv1x1x1(planes, planes * self.expansion)\n",
    "        self.bn3 = nn.BatchNorm3d(planes * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "    \n",
    "\n",
    "# Resnet structure\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 block,\n",
    "                 layers,\n",
    "                 block_inplanes,\n",
    "                 n_input_channels=1,\n",
    "                 conv1_t_size=7,\n",
    "                 conv1_t_stride=1,\n",
    "                 no_max_pool=False,\n",
    "                 shortcut_type='B',\n",
    "                 widen_factor=1.0,\n",
    "                 n_classes=360):\n",
    "        super().__init__()\n",
    "\n",
    "        block_inplanes = [int(x * widen_factor) for x in block_inplanes]\n",
    "\n",
    "        self.in_planes = block_inplanes[0]\n",
    "        self.no_max_pool = no_max_pool\n",
    "\n",
    "        self.conv1 = nn.Conv3d(n_input_channels,\n",
    "                               self.in_planes,\n",
    "                               kernel_size=(conv1_t_size, 7, 7),\n",
    "                               stride=(conv1_t_stride, 2, 2),\n",
    "                               padding=(conv1_t_size // 2, 3, 3),\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm3d(self.in_planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool3d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, block_inplanes[0], layers[0],\n",
    "                                       shortcut_type)\n",
    "        self.layer2 = self._make_layer(block,\n",
    "                                       block_inplanes[1],\n",
    "                                       layers[1],\n",
    "                                       shortcut_type,\n",
    "                                       stride=2)\n",
    "        self.layer3 = self._make_layer(block,\n",
    "                                       block_inplanes[2],\n",
    "                                       layers[2],\n",
    "                                       shortcut_type,\n",
    "                                       stride=2)\n",
    "        self.layer4 = self._make_layer(block,\n",
    "                                       block_inplanes[3],\n",
    "                                       layers[3],\n",
    "                                       shortcut_type,\n",
    "                                       stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool3d((1, 1, 1))\n",
    "        self.fc = nn.Linear(block_inplanes[3] * block.expansion, n_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv3d):\n",
    "                nn.init.kaiming_normal_(m.weight,\n",
    "                                        mode='fan_out',\n",
    "                                        nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm3d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _downsample_basic_block(self, x, planes, stride):\n",
    "        out = F.avg_pool3d(x, kernel_size=1, stride=stride)\n",
    "        zero_pads = torch.zeros(out.size(0), planes - out.size(1), out.size(2),\n",
    "                                out.size(3), out.size(4))\n",
    "        if isinstance(out.data, torch.cuda.FloatTensor):\n",
    "            zero_pads = zero_pads.cuda()\n",
    "\n",
    "        out = torch.cat([out.data, zero_pads], dim=1)\n",
    "\n",
    "        return out\n",
    "\n",
    "    # make layer helper function\n",
    "    def _make_layer(self, block, planes, blocks, shortcut_type, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.in_planes != planes * block.expansion:\n",
    "            \n",
    "                downsample = nn.Sequential(\n",
    "                    conv1x1x1(self.in_planes, planes * block.expansion, stride),\n",
    "                    nn.BatchNorm3d(planes * block.expansion))\n",
    "\n",
    "        layers = []\n",
    "        layers.append(\n",
    "            block(in_planes=self.in_planes,\n",
    "                  planes=planes,\n",
    "                  stride=stride,\n",
    "                  downsample=downsample))\n",
    "        self.in_planes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.in_planes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        if not self.no_max_pool:\n",
    "            x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "# Generates form of resnet\n",
    "def generate_model(model_depth, **kwargs):\n",
    "    assert model_depth in [10, 18, 34, 50, 101, 152, 200]\n",
    "\n",
    "    if model_depth == 10:\n",
    "        model = ResNet(BasicBlock, [1, 1, 1, 1], get_inplanes(), **kwargs)\n",
    "    elif model_depth == 18:\n",
    "        model = ResNet(BasicBlock, [2, 2, 2, 2], get_inplanes(), **kwargs)\n",
    "    elif model_depth == 34:\n",
    "        model = ResNet(BasicBlock, [3, 4, 6, 3], get_inplanes(), **kwargs)\n",
    "    elif model_depth == 50:\n",
    "        model = ResNet(Bottleneck, [3, 4, 6, 3], get_inplanes(), **kwargs)\n",
    "    elif model_depth == 101:\n",
    "        model = ResNet(Bottleneck, [3, 4, 23, 3], get_inplanes(), **kwargs)\n",
    "    elif model_depth == 152:\n",
    "        model = ResNet(Bottleneck, [3, 8, 36, 3], get_inplanes(), **kwargs)\n",
    "    elif model_depth == 200:\n",
    "        model = ResNet(Bottleneck, [3, 24, 36, 3], get_inplanes(), **kwargs)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e9f8c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "ResNet                                   [1, 360]                  --\n",
       "├─Conv3d: 1-1                            [1, 64, 180, 64, 92]      21,952\n",
       "├─BatchNorm3d: 1-2                       [1, 64, 180, 64, 92]      128\n",
       "├─ReLU: 1-3                              [1, 64, 180, 64, 92]      --\n",
       "├─MaxPool3d: 1-4                         [1, 64, 90, 32, 46]       --\n",
       "├─Sequential: 1-5                        [1, 256, 90, 32, 46]      --\n",
       "│    └─Bottleneck: 2-1                   [1, 256, 90, 32, 46]      --\n",
       "│    │    └─Conv3d: 3-1                  [1, 64, 90, 32, 46]       4,096\n",
       "│    │    └─BatchNorm3d: 3-2             [1, 64, 90, 32, 46]       128\n",
       "│    │    └─ReLU: 3-3                    [1, 64, 90, 32, 46]       --\n",
       "│    │    └─Conv3d: 3-4                  [1, 64, 90, 32, 46]       110,592\n",
       "│    │    └─BatchNorm3d: 3-5             [1, 64, 90, 32, 46]       128\n",
       "│    │    └─ReLU: 3-6                    [1, 64, 90, 32, 46]       --\n",
       "│    │    └─Conv3d: 3-7                  [1, 256, 90, 32, 46]      16,384\n",
       "│    │    └─BatchNorm3d: 3-8             [1, 256, 90, 32, 46]      512\n",
       "│    │    └─Sequential: 3-9              [1, 256, 90, 32, 46]      16,896\n",
       "│    │    └─ReLU: 3-10                   [1, 256, 90, 32, 46]      --\n",
       "│    └─Bottleneck: 2-2                   [1, 256, 90, 32, 46]      --\n",
       "│    │    └─Conv3d: 3-11                 [1, 64, 90, 32, 46]       16,384\n",
       "│    │    └─BatchNorm3d: 3-12            [1, 64, 90, 32, 46]       128\n",
       "│    │    └─ReLU: 3-13                   [1, 64, 90, 32, 46]       --\n",
       "│    │    └─Conv3d: 3-14                 [1, 64, 90, 32, 46]       110,592\n",
       "│    │    └─BatchNorm3d: 3-15            [1, 64, 90, 32, 46]       128\n",
       "│    │    └─ReLU: 3-16                   [1, 64, 90, 32, 46]       --\n",
       "│    │    └─Conv3d: 3-17                 [1, 256, 90, 32, 46]      16,384\n",
       "│    │    └─BatchNorm3d: 3-18            [1, 256, 90, 32, 46]      512\n",
       "│    │    └─ReLU: 3-19                   [1, 256, 90, 32, 46]      --\n",
       "│    └─Bottleneck: 2-3                   [1, 256, 90, 32, 46]      --\n",
       "│    │    └─Conv3d: 3-20                 [1, 64, 90, 32, 46]       16,384\n",
       "│    │    └─BatchNorm3d: 3-21            [1, 64, 90, 32, 46]       128\n",
       "│    │    └─ReLU: 3-22                   [1, 64, 90, 32, 46]       --\n",
       "│    │    └─Conv3d: 3-23                 [1, 64, 90, 32, 46]       110,592\n",
       "│    │    └─BatchNorm3d: 3-24            [1, 64, 90, 32, 46]       128\n",
       "│    │    └─ReLU: 3-25                   [1, 64, 90, 32, 46]       --\n",
       "│    │    └─Conv3d: 3-26                 [1, 256, 90, 32, 46]      16,384\n",
       "│    │    └─BatchNorm3d: 3-27            [1, 256, 90, 32, 46]      512\n",
       "│    │    └─ReLU: 3-28                   [1, 256, 90, 32, 46]      --\n",
       "├─Sequential: 1-6                        [1, 512, 45, 16, 23]      --\n",
       "│    └─Bottleneck: 2-4                   [1, 512, 45, 16, 23]      --\n",
       "│    │    └─Conv3d: 3-29                 [1, 128, 90, 32, 46]      32,768\n",
       "│    │    └─BatchNorm3d: 3-30            [1, 128, 90, 32, 46]      256\n",
       "│    │    └─ReLU: 3-31                   [1, 128, 90, 32, 46]      --\n",
       "│    │    └─Conv3d: 3-32                 [1, 128, 45, 16, 23]      442,368\n",
       "│    │    └─BatchNorm3d: 3-33            [1, 128, 45, 16, 23]      256\n",
       "│    │    └─ReLU: 3-34                   [1, 128, 45, 16, 23]      --\n",
       "│    │    └─Conv3d: 3-35                 [1, 512, 45, 16, 23]      65,536\n",
       "│    │    └─BatchNorm3d: 3-36            [1, 512, 45, 16, 23]      1,024\n",
       "│    │    └─Sequential: 3-37             [1, 512, 45, 16, 23]      132,096\n",
       "│    │    └─ReLU: 3-38                   [1, 512, 45, 16, 23]      --\n",
       "│    └─Bottleneck: 2-5                   [1, 512, 45, 16, 23]      --\n",
       "│    │    └─Conv3d: 3-39                 [1, 128, 45, 16, 23]      65,536\n",
       "│    │    └─BatchNorm3d: 3-40            [1, 128, 45, 16, 23]      256\n",
       "│    │    └─ReLU: 3-41                   [1, 128, 45, 16, 23]      --\n",
       "│    │    └─Conv3d: 3-42                 [1, 128, 45, 16, 23]      442,368\n",
       "│    │    └─BatchNorm3d: 3-43            [1, 128, 45, 16, 23]      256\n",
       "│    │    └─ReLU: 3-44                   [1, 128, 45, 16, 23]      --\n",
       "│    │    └─Conv3d: 3-45                 [1, 512, 45, 16, 23]      65,536\n",
       "│    │    └─BatchNorm3d: 3-46            [1, 512, 45, 16, 23]      1,024\n",
       "│    │    └─ReLU: 3-47                   [1, 512, 45, 16, 23]      --\n",
       "│    └─Bottleneck: 2-6                   [1, 512, 45, 16, 23]      --\n",
       "│    │    └─Conv3d: 3-48                 [1, 128, 45, 16, 23]      65,536\n",
       "│    │    └─BatchNorm3d: 3-49            [1, 128, 45, 16, 23]      256\n",
       "│    │    └─ReLU: 3-50                   [1, 128, 45, 16, 23]      --\n",
       "│    │    └─Conv3d: 3-51                 [1, 128, 45, 16, 23]      442,368\n",
       "│    │    └─BatchNorm3d: 3-52            [1, 128, 45, 16, 23]      256\n",
       "│    │    └─ReLU: 3-53                   [1, 128, 45, 16, 23]      --\n",
       "│    │    └─Conv3d: 3-54                 [1, 512, 45, 16, 23]      65,536\n",
       "│    │    └─BatchNorm3d: 3-55            [1, 512, 45, 16, 23]      1,024\n",
       "│    │    └─ReLU: 3-56                   [1, 512, 45, 16, 23]      --\n",
       "│    └─Bottleneck: 2-7                   [1, 512, 45, 16, 23]      --\n",
       "│    │    └─Conv3d: 3-57                 [1, 128, 45, 16, 23]      65,536\n",
       "│    │    └─BatchNorm3d: 3-58            [1, 128, 45, 16, 23]      256\n",
       "│    │    └─ReLU: 3-59                   [1, 128, 45, 16, 23]      --\n",
       "│    │    └─Conv3d: 3-60                 [1, 128, 45, 16, 23]      442,368\n",
       "│    │    └─BatchNorm3d: 3-61            [1, 128, 45, 16, 23]      256\n",
       "│    │    └─ReLU: 3-62                   [1, 128, 45, 16, 23]      --\n",
       "│    │    └─Conv3d: 3-63                 [1, 512, 45, 16, 23]      65,536\n",
       "│    │    └─BatchNorm3d: 3-64            [1, 512, 45, 16, 23]      1,024\n",
       "│    │    └─ReLU: 3-65                   [1, 512, 45, 16, 23]      --\n",
       "├─Sequential: 1-7                        [1, 1024, 23, 8, 12]      --\n",
       "│    └─Bottleneck: 2-8                   [1, 1024, 23, 8, 12]      --\n",
       "│    │    └─Conv3d: 3-66                 [1, 256, 45, 16, 23]      131,072\n",
       "│    │    └─BatchNorm3d: 3-67            [1, 256, 45, 16, 23]      512\n",
       "│    │    └─ReLU: 3-68                   [1, 256, 45, 16, 23]      --\n",
       "│    │    └─Conv3d: 3-69                 [1, 256, 23, 8, 12]       1,769,472\n",
       "│    │    └─BatchNorm3d: 3-70            [1, 256, 23, 8, 12]       512\n",
       "│    │    └─ReLU: 3-71                   [1, 256, 23, 8, 12]       --\n",
       "│    │    └─Conv3d: 3-72                 [1, 1024, 23, 8, 12]      262,144\n",
       "│    │    └─BatchNorm3d: 3-73            [1, 1024, 23, 8, 12]      2,048\n",
       "│    │    └─Sequential: 3-74             [1, 1024, 23, 8, 12]      526,336\n",
       "│    │    └─ReLU: 3-75                   [1, 1024, 23, 8, 12]      --\n",
       "│    └─Bottleneck: 2-9                   [1, 1024, 23, 8, 12]      --\n",
       "│    │    └─Conv3d: 3-76                 [1, 256, 23, 8, 12]       262,144\n",
       "│    │    └─BatchNorm3d: 3-77            [1, 256, 23, 8, 12]       512\n",
       "│    │    └─ReLU: 3-78                   [1, 256, 23, 8, 12]       --\n",
       "│    │    └─Conv3d: 3-79                 [1, 256, 23, 8, 12]       1,769,472\n",
       "│    │    └─BatchNorm3d: 3-80            [1, 256, 23, 8, 12]       512\n",
       "│    │    └─ReLU: 3-81                   [1, 256, 23, 8, 12]       --\n",
       "│    │    └─Conv3d: 3-82                 [1, 1024, 23, 8, 12]      262,144\n",
       "│    │    └─BatchNorm3d: 3-83            [1, 1024, 23, 8, 12]      2,048\n",
       "│    │    └─ReLU: 3-84                   [1, 1024, 23, 8, 12]      --\n",
       "│    └─Bottleneck: 2-10                  [1, 1024, 23, 8, 12]      --\n",
       "│    │    └─Conv3d: 3-85                 [1, 256, 23, 8, 12]       262,144\n",
       "│    │    └─BatchNorm3d: 3-86            [1, 256, 23, 8, 12]       512\n",
       "│    │    └─ReLU: 3-87                   [1, 256, 23, 8, 12]       --\n",
       "│    │    └─Conv3d: 3-88                 [1, 256, 23, 8, 12]       1,769,472\n",
       "│    │    └─BatchNorm3d: 3-89            [1, 256, 23, 8, 12]       512\n",
       "│    │    └─ReLU: 3-90                   [1, 256, 23, 8, 12]       --\n",
       "│    │    └─Conv3d: 3-91                 [1, 1024, 23, 8, 12]      262,144\n",
       "│    │    └─BatchNorm3d: 3-92            [1, 1024, 23, 8, 12]      2,048\n",
       "│    │    └─ReLU: 3-93                   [1, 1024, 23, 8, 12]      --\n",
       "│    └─Bottleneck: 2-11                  [1, 1024, 23, 8, 12]      --\n",
       "│    │    └─Conv3d: 3-94                 [1, 256, 23, 8, 12]       262,144\n",
       "│    │    └─BatchNorm3d: 3-95            [1, 256, 23, 8, 12]       512\n",
       "│    │    └─ReLU: 3-96                   [1, 256, 23, 8, 12]       --\n",
       "│    │    └─Conv3d: 3-97                 [1, 256, 23, 8, 12]       1,769,472\n",
       "│    │    └─BatchNorm3d: 3-98            [1, 256, 23, 8, 12]       512\n",
       "│    │    └─ReLU: 3-99                   [1, 256, 23, 8, 12]       --\n",
       "│    │    └─Conv3d: 3-100                [1, 1024, 23, 8, 12]      262,144\n",
       "│    │    └─BatchNorm3d: 3-101           [1, 1024, 23, 8, 12]      2,048\n",
       "│    │    └─ReLU: 3-102                  [1, 1024, 23, 8, 12]      --\n",
       "│    └─Bottleneck: 2-12                  [1, 1024, 23, 8, 12]      --\n",
       "│    │    └─Conv3d: 3-103                [1, 256, 23, 8, 12]       262,144\n",
       "│    │    └─BatchNorm3d: 3-104           [1, 256, 23, 8, 12]       512\n",
       "│    │    └─ReLU: 3-105                  [1, 256, 23, 8, 12]       --\n",
       "│    │    └─Conv3d: 3-106                [1, 256, 23, 8, 12]       1,769,472\n",
       "│    │    └─BatchNorm3d: 3-107           [1, 256, 23, 8, 12]       512\n",
       "│    │    └─ReLU: 3-108                  [1, 256, 23, 8, 12]       --\n",
       "│    │    └─Conv3d: 3-109                [1, 1024, 23, 8, 12]      262,144\n",
       "│    │    └─BatchNorm3d: 3-110           [1, 1024, 23, 8, 12]      2,048\n",
       "│    │    └─ReLU: 3-111                  [1, 1024, 23, 8, 12]      --\n",
       "│    └─Bottleneck: 2-13                  [1, 1024, 23, 8, 12]      --\n",
       "│    │    └─Conv3d: 3-112                [1, 256, 23, 8, 12]       262,144\n",
       "│    │    └─BatchNorm3d: 3-113           [1, 256, 23, 8, 12]       512\n",
       "│    │    └─ReLU: 3-114                  [1, 256, 23, 8, 12]       --\n",
       "│    │    └─Conv3d: 3-115                [1, 256, 23, 8, 12]       1,769,472\n",
       "│    │    └─BatchNorm3d: 3-116           [1, 256, 23, 8, 12]       512\n",
       "│    │    └─ReLU: 3-117                  [1, 256, 23, 8, 12]       --\n",
       "│    │    └─Conv3d: 3-118                [1, 1024, 23, 8, 12]      262,144\n",
       "│    │    └─BatchNorm3d: 3-119           [1, 1024, 23, 8, 12]      2,048\n",
       "│    │    └─ReLU: 3-120                  [1, 1024, 23, 8, 12]      --\n",
       "├─Sequential: 1-8                        [1, 2048, 12, 4, 6]       --\n",
       "│    └─Bottleneck: 2-14                  [1, 2048, 12, 4, 6]       --\n",
       "│    │    └─Conv3d: 3-121                [1, 512, 23, 8, 12]       524,288\n",
       "│    │    └─BatchNorm3d: 3-122           [1, 512, 23, 8, 12]       1,024\n",
       "│    │    └─ReLU: 3-123                  [1, 512, 23, 8, 12]       --\n",
       "│    │    └─Conv3d: 3-124                [1, 512, 12, 4, 6]        7,077,888\n",
       "│    │    └─BatchNorm3d: 3-125           [1, 512, 12, 4, 6]        1,024\n",
       "│    │    └─ReLU: 3-126                  [1, 512, 12, 4, 6]        --\n",
       "│    │    └─Conv3d: 3-127                [1, 2048, 12, 4, 6]       1,048,576\n",
       "│    │    └─BatchNorm3d: 3-128           [1, 2048, 12, 4, 6]       4,096\n",
       "│    │    └─Sequential: 3-129            [1, 2048, 12, 4, 6]       2,101,248\n",
       "│    │    └─ReLU: 3-130                  [1, 2048, 12, 4, 6]       --\n",
       "│    └─Bottleneck: 2-15                  [1, 2048, 12, 4, 6]       --\n",
       "│    │    └─Conv3d: 3-131                [1, 512, 12, 4, 6]        1,048,576\n",
       "│    │    └─BatchNorm3d: 3-132           [1, 512, 12, 4, 6]        1,024\n",
       "│    │    └─ReLU: 3-133                  [1, 512, 12, 4, 6]        --\n",
       "│    │    └─Conv3d: 3-134                [1, 512, 12, 4, 6]        7,077,888\n",
       "│    │    └─BatchNorm3d: 3-135           [1, 512, 12, 4, 6]        1,024\n",
       "│    │    └─ReLU: 3-136                  [1, 512, 12, 4, 6]        --\n",
       "│    │    └─Conv3d: 3-137                [1, 2048, 12, 4, 6]       1,048,576\n",
       "│    │    └─BatchNorm3d: 3-138           [1, 2048, 12, 4, 6]       4,096\n",
       "│    │    └─ReLU: 3-139                  [1, 2048, 12, 4, 6]       --\n",
       "│    └─Bottleneck: 2-16                  [1, 2048, 12, 4, 6]       --\n",
       "│    │    └─Conv3d: 3-140                [1, 512, 12, 4, 6]        1,048,576\n",
       "│    │    └─BatchNorm3d: 3-141           [1, 512, 12, 4, 6]        1,024\n",
       "│    │    └─ReLU: 3-142                  [1, 512, 12, 4, 6]        --\n",
       "│    │    └─Conv3d: 3-143                [1, 512, 12, 4, 6]        7,077,888\n",
       "│    │    └─BatchNorm3d: 3-144           [1, 512, 12, 4, 6]        1,024\n",
       "│    │    └─ReLU: 3-145                  [1, 512, 12, 4, 6]        --\n",
       "│    │    └─Conv3d: 3-146                [1, 2048, 12, 4, 6]       1,048,576\n",
       "│    │    └─BatchNorm3d: 3-147           [1, 2048, 12, 4, 6]       4,096\n",
       "│    │    └─ReLU: 3-148                  [1, 2048, 12, 4, 6]       --\n",
       "├─AdaptiveAvgPool3d: 1-9                 [1, 2048, 1, 1, 1]        --\n",
       "├─Linear: 1-10                           [1, 360]                  737,640\n",
       "==========================================================================================\n",
       "Total params: 46,892,712\n",
       "Trainable params: 46,892,712\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 166.72\n",
       "==========================================================================================\n",
       "Input size (MB): 16.96\n",
       "Forward/backward pass size (MB): 5744.99\n",
       "Params size (MB): 187.57\n",
       "Estimated Total Size (MB): 5949.52\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = generate_model(50)\n",
    "summary(model, (1, 1, 180, 128, 184))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dae74d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleared Cache.\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "print(\"Cleared Cache.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60436868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n",
      "Epoch: 0   Training Loss: 8.675937435150146 \n",
      "Epoch: 0   Validation Loss: 8.637215789794922 \n",
      "Epoch: 1   Training Loss: 8.550091216087342 \n",
      "Epoch: 1   Validation Loss: 8.634143383026123 \n",
      "Epoch: 2   Training Loss: 8.548500755786895 \n",
      "Epoch: 2   Validation Loss: 8.634987831115723 \n",
      "Epoch: 3   Training Loss: 8.54633942747116 \n",
      "Epoch: 3   Validation Loss: 8.634380920410155 \n",
      "Epoch: 4   Training Loss: 8.54618415927887 \n",
      "Epoch: 4   Validation Loss: 8.63404622077942 \n",
      "Epoch: 5   Training Loss: 8.544558280467987 \n",
      "Epoch: 5   Validation Loss: 8.636162494659423 \n",
      "Epoch: 6   Training Loss: 8.5445187997818 \n",
      "Epoch: 6   Validation Loss: 8.637802011489867 \n",
      "Epoch: 7   Training Loss: 8.54340375137329 \n",
      "Epoch: 7   Validation Loss: 8.636956958770751 \n",
      "Epoch: 8   Training Loss: 8.541249145507813 \n",
      "Epoch: 8   Validation Loss: 8.638404209136963 \n",
      "Epoch: 9   Training Loss: 8.539491621017456 \n",
      "Epoch: 9   Validation Loss: 8.642688968658447 \n",
      "Epoch: 10   Training Loss: 8.539868073940276 \n",
      "Epoch: 10   Validation Loss: 8.638388414382934 \n",
      "Epoch: 11   Training Loss: 8.535789679527282 \n",
      "Epoch: 11   Validation Loss: 8.659296237945556 \n",
      "Epoch: 12   Training Loss: 8.540647621631622 \n",
      "Epoch: 12   Validation Loss: 8.640927856445312 \n",
      "Epoch: 13   Training Loss: 8.536412020206452 \n",
      "Epoch: 13   Validation Loss: 8.638349208831787 \n",
      "Epoch: 14   Training Loss: 8.533253874301911 \n",
      "Epoch: 14   Validation Loss: 8.643367462158203 \n",
      "Epoch: 15   Training Loss: 8.527924956798554 \n",
      "Epoch: 15   Validation Loss: 8.639724937438965 \n",
      "Epoch: 16   Training Loss: 8.526443465709686 \n",
      "Epoch: 16   Validation Loss: 8.641049837112426 \n",
      "Epoch: 17   Training Loss: 8.525494493961334 \n",
      "Epoch: 17   Validation Loss: 8.637919031143188 \n",
      "Epoch: 18   Training Loss: 8.52088832807541 \n",
      "Epoch: 18   Validation Loss: 8.640385269165039 \n",
      "Epoch: 19   Training Loss: 8.5135285282135 \n",
      "Epoch: 19   Validation Loss: 8.647496259689332 \n",
      "Epoch: 20   Training Loss: 8.505029215812684 \n",
      "Epoch: 20   Validation Loss: 8.65692091369629 \n",
      "Epoch: 21   Training Loss: 8.499331664562225 \n",
      "Epoch: 21   Validation Loss: 8.651652091979981 \n",
      "Epoch: 22   Training Loss: 8.492654026031493 \n",
      "Epoch: 22   Validation Loss: 8.65613045501709 \n",
      "Epoch: 23   Training Loss: 8.486072044849395 \n",
      "Epoch: 23   Validation Loss: 8.669032152175904 \n",
      "Epoch: 24   Training Loss: 8.474200892448426 \n",
      "Epoch: 24   Validation Loss: 8.670946012496948 \n",
      "Epoch: 25   Training Loss: 8.459878311157226 \n",
      "Epoch: 25   Validation Loss: 8.676813571929932 \n",
      "Epoch: 26   Training Loss: 8.44530787754059 \n",
      "Epoch: 26   Validation Loss: 8.694259372711182 \n",
      "Epoch: 27   Training Loss: 8.430397122383118 \n",
      "Epoch: 27   Validation Loss: 8.69792946434021 \n",
      "Epoch: 28   Training Loss: 8.413688917160034 \n",
      "Epoch: 28   Validation Loss: 8.696765251159668 \n",
      "Epoch: 29   Training Loss: 8.399037785053252 \n",
      "Epoch: 29   Validation Loss: 8.691826942443848 \n",
      "Epoch: 30   Training Loss: 8.376592763900756 \n",
      "Epoch: 30   Validation Loss: 8.7027394657135 \n",
      "Epoch: 31   Training Loss: 8.345824987888337 \n",
      "Epoch: 31   Validation Loss: 8.724213249206542 \n",
      "Epoch: 32   Training Loss: 8.317345552444458 \n",
      "Epoch: 32   Validation Loss: 8.714600950241088 \n",
      "Epoch: 33   Training Loss: 8.281286535739898 \n",
      "Epoch: 33   Validation Loss: 8.7247602558136 \n",
      "Epoch: 34   Training Loss: 8.244401223659516 \n",
      "Epoch: 34   Validation Loss: 8.744323307037353 \n",
      "Epoch: 35   Training Loss: 8.208998323917388 \n",
      "Epoch: 35   Validation Loss: 8.737890970230103 \n",
      "Epoch: 36   Training Loss: 8.17324357509613 \n",
      "Epoch: 36   Validation Loss: 8.79203404045105 \n",
      "Epoch: 37   Training Loss: 8.112245694637298 \n",
      "Epoch: 37   Validation Loss: 8.82022032546997 \n",
      "Epoch: 38   Training Loss: 8.055540256500244 \n",
      "Epoch: 38   Validation Loss: 8.824949758529662 \n",
      "Epoch: 39   Training Loss: 8.001652318000794 \n",
      "Epoch: 39   Validation Loss: 8.875130348205566 \n",
      "Epoch: 40   Training Loss: 7.944517226219177 \n",
      "Epoch: 40   Validation Loss: 8.92342423248291 \n",
      "Epoch: 41   Training Loss: 7.887668593406677 \n",
      "Epoch: 41   Validation Loss: 8.869113842010497 \n",
      "Epoch: 42   Training Loss: 7.845277650356293 \n",
      "Epoch: 42   Validation Loss: 8.91486049079895 \n",
      "Epoch: 43   Training Loss: 7.764593936920166 \n",
      "Epoch: 43   Validation Loss: 8.97461205482483 \n",
      "Epoch: 44   Training Loss: 7.687243934631348 \n",
      "Epoch: 44   Validation Loss: 9.00175478553772 \n",
      "Epoch: 45   Training Loss: 7.6072951827049256 \n",
      "Epoch: 45   Validation Loss: 9.084721183776855 \n",
      "Epoch: 46   Training Loss: 7.546590400695801 \n",
      "Epoch: 46   Validation Loss: 9.423148387908936 \n",
      "Epoch: 47   Training Loss: 7.475161081314087 \n",
      "Epoch: 47   Validation Loss: 9.437193037033081 \n",
      "Epoch: 48   Training Loss: 7.378966382980346 \n",
      "Epoch: 48   Validation Loss: 9.439676120758056 \n",
      "Epoch: 49   Training Loss: 7.306868016719818 \n",
      "Epoch: 49   Validation Loss: 9.156148389816284 \n",
      "Epoch: 50   Training Loss: 7.213011604309082 \n",
      "Epoch: 50   Validation Loss: 9.154379053115845 \n",
      "Epoch: 51   Training Loss: 7.121198570251464 \n",
      "Epoch: 51   Validation Loss: 9.131105880737305 \n",
      "Epoch: 52   Training Loss: 7.009476673841476 \n",
      "Epoch: 52   Validation Loss: 9.23526985359192 \n",
      "Epoch: 53   Training Loss: 6.891162949800491 \n",
      "Epoch: 53   Validation Loss: 9.42442054748535 \n",
      "Epoch: 54   Training Loss: 6.761086081504822 \n",
      "Epoch: 54   Validation Loss: 9.499693630218506 \n",
      "Epoch: 55   Training Loss: 6.636378908395767 \n",
      "Epoch: 55   Validation Loss: 9.634083541870117 \n",
      "Epoch: 56   Training Loss: 6.539673368930817 \n",
      "Epoch: 56   Validation Loss: 9.695492334365845 \n",
      "Epoch: 57   Training Loss: 6.376272210597992 \n",
      "Epoch: 57   Validation Loss: 9.703313404083252 \n",
      "Epoch: 58   Training Loss: 6.2353317348957065 \n",
      "Epoch: 58   Validation Loss: 9.979148445129395 \n",
      "Epoch: 59   Training Loss: 6.0748138136863705 \n",
      "Epoch: 59   Validation Loss: 10.36939796257019 \n",
      "Epoch: 60   Training Loss: 5.8956287837028505 \n",
      "Epoch: 60   Validation Loss: 10.282306297302245 \n",
      "Epoch: 61   Training Loss: 5.766915154695511 \n",
      "Epoch: 61   Validation Loss: 10.373284982681275 \n",
      "Epoch: 62   Training Loss: 5.596035237669945 \n",
      "Epoch: 62   Validation Loss: 10.437708574295044 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 34\u001b[0m\n\u001b[1;32m     30\u001b[0m test_epoch_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trainset, \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m---> 34\u001b[0m     inputs, truths \u001b[38;5;241m=\u001b[39m norm(torch\u001b[38;5;241m.\u001b[39mfrom_numpy(data[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mfloat()), torch\u001b[38;5;241m.\u001b[39mfrom_numpy(data[\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m     35\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     37\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m net(inputs)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "# Create writer and profiler to analyze loss over each epoch\n",
    "writer = SummaryWriter()\n",
    "\n",
    "# Set device to CUDA if available, initialize model\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device: {}'.format(device))\n",
    "net = generate_model(50)\n",
    "net.to(device)\n",
    "\n",
    "# Set up optimizer and loss function, set number of epochs\n",
    "optimizer = optim.SGD(net.parameters(), lr = 5e-2, momentum=0.9, weight_decay = 0)\n",
    "criterion = nn.MSELoss(reduction = 'mean')\n",
    "criterion.to(device)\n",
    "num_epochs = 500\n",
    "\n",
    "# Iniitializing variables to show statistics\n",
    "iteration = 0\n",
    "test_iteration = 0\n",
    "loss_list = []\n",
    "test_loss_list = []\n",
    "epoch_loss_averages = []\n",
    "test_epoch_loss_averages = []\n",
    "\n",
    "# Iterates over dataset multiple times\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    test_epoch_loss = 0\n",
    "    \n",
    "    for i, data in enumerate(trainset, 0):\n",
    "        \n",
    "        inputs, truths = norm(torch.from_numpy(data[0]).to(device).float()), torch.from_numpy(data[1]).to(device).float()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs).to(device)\n",
    "        loss = criterion(outputs, truths)\n",
    "        writer.add_scalar(\"Loss / Train\", loss, epoch) # adds training loss scalar\n",
    "        loss_list.append(loss.cpu().detach().numpy())\n",
    "        epoch_loss += loss.cpu().detach().numpy()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        iteration += 1\n",
    "        if iteration % trainset.shape[0] == 0:\n",
    "            epoch_loss_averages.append(epoch_loss / trainset.shape[0])\n",
    "            print('Epoch: {}   Training Loss: {} '.format(epoch, epoch_loss / trainset.shape[0]))\n",
    "            \n",
    "    for i, test_data in enumerate(testset, 0):\n",
    "        \n",
    "        inputs, truths = norm(torch.from_numpy(test_data[0]).to(device).float()), torch.from_numpy(test_data[1]).to(device).float()\n",
    "        outputs = net(inputs).to(device)\n",
    "        test_loss = criterion(outputs, truths)\n",
    "        \n",
    "        writer.add_scalar(\"Loss / Test\", test_loss, epoch) # adds testing loss scalar\n",
    "        test_loss_list.append(test_loss.cpu().detach().numpy())\n",
    "        test_epoch_loss += test_loss.cpu().detach().numpy()\n",
    "        \n",
    "        test_iteration +=1\n",
    "        if test_iteration % testset.shape[0] == 0:\n",
    "            test_epoch_loss_averages.append(test_epoch_loss / testset.shape[0])\n",
    "            print('Epoch: {}   Validation Loss: {} '.format(epoch, test_epoch_loss / testset.shape[0]))\n",
    "            \n",
    "writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "541b594f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot epoch loss to test for convergence\n",
    "plt.plot(epoch_loss_averages)\n",
    "plt.plot(test_epoch_loss_averages)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716136ea",
   "metadata": {},
   "source": [
    "This shows that there is still not testing convergence, so an alternative method will be tested."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
